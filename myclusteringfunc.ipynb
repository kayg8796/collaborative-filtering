{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import statistics\n",
    "import csv\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from numpy import dot\n",
    "\n",
    "class kmeans:\n",
    "\n",
    "    def __init__(self, n_clusters, max_iter=100):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "        \n",
    "    def jaccard_similarity(self,a,b):\n",
    "        a=set(a)\n",
    "        b=set(b)\n",
    "        s1=a.intersection(b)\n",
    "        s2=a.union(b)\n",
    "        return len(s1)/len(s2)\n",
    "    \n",
    "    def cosine_similarity(self,v1,v2):\n",
    "        return dot(v1, v2)/(norm(v1)*norm(v2))\n",
    "\n",
    "    def initializ_centroids(self, X): # other initialization\n",
    "        random_idx = np.random.permutation(X.shape[0])\n",
    "        centroids = X[random_idx[:self.n_clusters]]\n",
    "        return centroids\n",
    "\n",
    "    def compute_centroids(self, X, labels):\n",
    "        centroids = np.zeros((self.n_clusters, X.shape[1]))\n",
    "        for k in range(self.n_clusters):\n",
    "            centroids[k, :] = np.mean(X[labels == k, :], axis=0)\n",
    "        return centroids\n",
    "    \n",
    "    def metadata(self,dfc,labels):\n",
    "        cluster_num = self.n_clusters\n",
    "        y= dfc[:,0]\n",
    "        X = dfc[:,1:]  #preparing values in numpy format\n",
    "        sum = np.zeros((cluster_num, X.shape[1]))\n",
    "        sum_sq = np.zeros((cluster_num, X.shape[1]))\n",
    "        N = np.zeros(cluster_num)\n",
    "        #new_centroids = np.zeros((cluster_num, X.shape[1]))     #new centroids\n",
    "        movieid = []\n",
    "        for k in range(cluster_num):\n",
    "            sum[k,:] = np.sum(X[labels==k,:],axis=0)\n",
    "            sum_sq[k,:]=  np.sum((X[labels==k,:])**2,axis=0) \n",
    "            N[k] = X[labels==k].shape[0] \n",
    "            #new_centroids[k] = sum[k]/N[k]\n",
    "            movieid.append(list(y[labels==k]))\n",
    "        return (N,sum,sum_sq,movieid)\n",
    "    \n",
    "\n",
    "\n",
    "    def compute_distance(self, X, centroids):\n",
    "        distance = np.zeros((X.shape[0], self.n_clusters))\n",
    "        for k in range(self.n_clusters):\n",
    "            for j in range(X.shape[0]):\n",
    "                distance[j][k]=self.cosine_similarity(X[j],centroids[k])\n",
    "        #pring(distance.shape)\n",
    "        return distance\n",
    "\n",
    "\n",
    "    \n",
    "    def centroids(self, X):\n",
    "        self.centroids = self.initializ_centroids(X[:,1:])\n",
    "        for i in range(self.max_iter):  #it would summarise any x input giveen to it\n",
    "            old_centroids = self.centroids\n",
    "            distance = self.compute_distance(X[:,1:], old_centroids)\n",
    "            self.labels = np.argmax(distance,axis=1) # finding closest distance returns an array of row indices for which \n",
    "            self.centroids = self.compute_centroids(X[:,1:], self.labels) \n",
    "            if np.all(old_centroids == self.centroids):\n",
    "                #print(self.centroids)\n",
    "                return self.metadata(X,self.labels)\n",
    "        return self.metadata(X,self.labels) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "class bfr:\n",
    "\n",
    "    def __init__(self, n_clusters,meta, max_iter=100):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.meta = meta\n",
    "        self.centroids = self.compute_centroids(self.meta,self.n_clusters)\n",
    "\n",
    "    \n",
    "    def jaccard_similarity(self,a,b):\n",
    "        a=set(a)\n",
    "        b=set(b)\n",
    "        s1=a.intersection(b)\n",
    "        s2=a.union(b)\n",
    "        return len(s1)/len(s2)\n",
    "    \n",
    "    def cosine_similarity(self,v1,v2):\n",
    "        denom = norm(v1)*norm(v2)\n",
    "        if denom == 0 :\n",
    "            denom = 0.00000001\n",
    "        return dot(v1, v2)/denom\n",
    "    \n",
    "    def compute_centroids(self, summary,cluster_num):  #takes in summed summary\n",
    "        centroids = np.zeros((cluster_num, len(summary[1][1])))\n",
    "        for k in range(cluster_num):\n",
    "            centroids[k, :] = summary[1][k]/summary[0][k]\n",
    "        return centroids\n",
    "    \n",
    "\n",
    "    \n",
    "    def metadata(self,dfc,labels,cluster_num):\n",
    "        y= dfc[:,0]\n",
    "        X=dfc[:,1:]\n",
    "        sum = np.zeros((cluster_num, X.shape[1]))\n",
    "        sum_sq = np.zeros((cluster_num, X.shape[1]))\n",
    "        N = np.zeros(cluster_num)\n",
    "        #new_centroids = np.zeros((cluster_num, X.shape[1]))     #new centroids\n",
    "        movieid = []\n",
    "        for k in range(cluster_num):\n",
    "            sum[k,:] = np.sum(X[labels==k,:],axis=0)   + self.meta[1][k]\n",
    "            sum_sq[k,:]=  np.sum((X[labels==k,:])**2,axis=0) + self.meta[2][k]\n",
    "            N[k] = X[labels==k].shape[0] + self.meta[0][k]\n",
    "            #new_centroids[k] = sum[k]/N[k]\n",
    "            movieid.append(list(y[labels==k]))\n",
    "            #movieid[k].extend(self.meta[3][k])\n",
    "        return (N,sum,sum_sq,movieid)\n",
    "    \n",
    "\n",
    "\n",
    "    def compute_distance(self, X, centroids,cluster_num):\n",
    "        distance = np.zeros((X.shape[0], cluster_num))\n",
    "        #print(len(centroids))\n",
    "        for k in range(cluster_num):\n",
    "            for j in range(X.shape[0]):\n",
    "                distance[j][k]=self.cosine_similarity(X[j],centroids[k])  #centroid is the k column\n",
    "        #pring(distance.shape)\n",
    "        return distance\n",
    "\n",
    "\n",
    "    \n",
    "    def summarize(self, X):  #expects a centroid input\n",
    "        distance = self.compute_distance(X[:,1:], self.centroids,self.n_clusters)\n",
    "        self.labels = np.argmax(distance,axis=1) # finding closest distance returns an array of row indices for which \n",
    "        self.lab_dist = np.max(distance,axis=1)\n",
    "        return self.metadata(X,self.labels,self.n_clusters) # take in dfd here and mordify metadata, dfd has all required information\n",
    "            \n",
    "    def active_centroid(self):\n",
    "        return self.centroids\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(n):\n",
    "    file = open('item_based.csv','r',buffering=100000,encoding='utf-8')\n",
    "    chunk_num=0\n",
    "    results = ''\n",
    "    f=[]\n",
    "    wr=[]\n",
    "    for i in range(n):\n",
    "        f.append(open('cluster'+str(i)+'.csv','a',newline='',encoding='utf-8'))\n",
    "        wr.append(csv.writer(f[i], delimiter=','))\n",
    "    while True:\n",
    "        c=0\n",
    "        tt=[]\n",
    "        for line in file:\n",
    "            tt.append(line.replace('\\n','').split(','))\n",
    "            c += 1\n",
    "            if c==200:\n",
    "                break \n",
    "        tt=np.array(tt)\n",
    "        tt1=copy.deepcopy(tt)                                  #added\n",
    "        tt1[np.where(tt1=='')]=np.nan\n",
    "        tx=pd.DataFrame(np.array(tt1[:,1:],dtype='f'))\n",
    "        #print(tx.head(20))\n",
    "        tx=np.array(tx.apply(lambda x: x-np.mean(x),axis=1).fillna(0))\n",
    "        #print('GOT HERE')\n",
    "        #tx=np.array(tt1[:,1:],dtype='f')\n",
    "        ind=np.arange(0,tt.shape[0])\n",
    "        ind =ind.reshape([-1,1])\n",
    "        ty=np.concatenate((ind,tx),axis=1)\n",
    "        if chunk_num ==0 :\n",
    "            kr=kmeans(n)\n",
    "            results=kr.centroids(ty)\n",
    "            chunk_num += 1\n",
    "        else:\n",
    "            ck = bfr(n,results)\n",
    "            results = ck.summarize(ty) \n",
    "        for i in range(len(results[3])):\n",
    "            for j in results[3][i]:\n",
    "                #results1[i].append(tt[int(j),:])\n",
    "                wr[i].writerow(tt[int(j),:])\n",
    "        if c<200:\n",
    "            break\n",
    "    file.close()\n",
    "    for i in range(n):\n",
    "        f[i].close()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    n=input('Please Enter the number of clusters k :')\n",
    "    print('Please wait\\nGenerating Clusters........')\n",
    "    clustering(int(n))\n",
    "    print('Done...Please check output files')\n",
    "    return\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
